Role: You are a senior Digital SAT examiner with expertise in creating SAT Reading and Writing practice tests. Your task is to create a practice test for the SAT Reading and Writing digital test. The test should contain **at least 10 questions** with answers and explanations, designed to help a student improve their score from **700 to 800**. Follow these steps:

---

## Step-by-Step Instructions

### **Step 1: Understand the SAT Reading and Writing Domains and Skills**
Refer to the SAT Reading and Writing guide provided. Ensure the questions align with the **four content domains** and their respective skills:

- **Information and Ideas**: Measures comprehension, analysis, and reasoning skills and knowledge and the ability to locate, interpret, evaluate, and integrate information and ideas from texts and informational graphics (tables, bar graphs, and line graphs).
  - Central Ideas and Details
  - Command of Evidence (Textual, Quantitative)
  - Inferences
- **Craft and Structure**: Measures the comprehension, vocabulary, analysis, synthesis, and reasoning skills and knowledge needed to understand and use high-utility words and phrases in context, evaluate texts rhetorically, and make connections between topically related texts.
  - Words in Context
  - Text Structure and Purpose
  - Cross-Text Connections
- **Expression of Ideas**: Measures the ability to revise texts to improve the effectiveness of written expression and to meet specific rhetorical goals.
  - Rhetorical Synthesis
  - Transitions
- **Standard English Conventions**: Measures the ability to edit text to conform to core conventions of Standard English sentence structure, usage, and punctuation.
  - Boundaries
  - Form, Structure, and Sense

---

### **Step 2: Divide the Provided Article into Logical Passages**

Use the following provided parts of Essay (markdown format), **"The Uniqueness Trap" by Bent Flyvbjerg (Harvard Business Review USA, March-April, 2025)**, and pick from or merge the provided content into **multiple meaningful passages**. Each passage should：

- Be self-contained and coherent.
- Contains 1 or more paragraphs.
- Be suitable for generating one or two SAT-style questions.
- Include enough detail to support at least one question.
- Range from 25 to 150 words.

Here is the article:
"

To quantify the effect of perceived uniqueness on projects, we asked the managers of each of the 219 projects in our sample to indicate, on a scale of one to 10, how much they agreed with the statement “This project is unique, and therefore it is difficult to compare with other projects.” Twenty-seven percent gave their project a score of seven or higher.

Next we tested the association between perceived uniqueness and performance, which we assessed by measuring the benefits delivered and cost and schedule overruns. The results supported our hypothesis that project leaders’ view of projects as unique was correlated with underperformance. We found that a one-point increase on the 10-point scale was associated, on average, with a five-percentage-point increase in cost overruns. That meant that in projects receiving the highest rating—a 10—cost overruns were 45 percentage points higher, on average, than overruns in projects receiving the lowest rating (a one). Worryingly, in 37% of the projects rated a 10, the cost overrun was extreme—exceeding the budget by more than 75%.

It should be noted that the above conclusions are based on perceived uniqueness. As we discovered, the perceptions didn’t necessarily match reality.

The short answer is no. In fact, whenever we came across a project we thought was unique, it turned out not to be. Here’s an example: In 2004 the top civil servant in charge of decommissioning nuclear power plants in Sweden needed a reliable estimate of how much that effort, which would take decades, would cost, as well as how expensive it would be to safely store nuclear waste, which would last centuries. The Swedish government was going to ask the nuclear industry to pay into a fund to cover the costs, and it needed to know how much to collect.

The Swedish official approached one of us, Bent Flyv bjerg, for advice. Bent didn’t think he could help. At the time he didn’t have any data on nuclear decommissioning. No other country had carried out such a program. (Decommissioning nuclear plants has become more common since then.) The project truly did seem unique. But the Swedish official had read an article Bent had written about the costs and cost risks for transportation infrastructure projects involving roads, bridges, tunnels, and rail lines. He proposed using Bent’s data as a “floor” and assuming that the real cost risks of nuclear decommissioning would be higher. The Swedish government could get the nuclear industry to start making payments based on the floor and then adjust the estimate and the payments as it learned more about decommissioning. Bent realized that he had fallen into the uniqueness trap by assuming that the manager of a project as unprecedented as nuclear decommissioning would have nothing to learn from other projects. He has never forgotten that lesson.

Were the managers in our sample of IT projects similarly mistaken? We looked at the 59 projects with a perceived uniqueness score of seven or higher and compared their functional scope, descriptions, and start dates against those of 6,219 other projects in another, larger database. We found that with all 59 projects, including those rated a nine or a 10, a similar project had, in fact, previously been executed in the same organization or the same industry. In other words, none of the projects could be considered unique. For example, five of the 59 projects were regulatory-compliance projects in banks. We established not only that each of the banks in question had completed similar regulatory efforts before but also that every other bank in its relevant jurisdiction was working to address the same type of regulation at the same time.

On that basis we concluded that many more projects are perceived as unique than actually are and that perceived and actual uniqueness are not correlated. We also found that perceived uniqueness is what matters to project performance, because when managers think there is nothing to learn from other endeavors, the lack of learning will hamper their projects.

Our study suggests that the bias is linked to certain project features. Perceived uniqueness was generally correlated with a project’s complexity, its political sensitivity, its number of unknown variables, and the extent to which its requirements shifted. But none of those characteristics had a statistically significant effect on their own, which implied that they could not by themselves explain extreme cost overruns. From a statistical perspective, the uniqueness bias was the cause of the overruns, and despite the correlations, it was not rooted in a project’s complexity, sensitivity, uncertainty, or requirements.

So where did the bias come from? One strong possibility is that it resulted from the tendency to assume that what’s unique to you will be unique to everyone. For instance, California has never built a high-speed rail line before, so in that sense, the recent efforts to construct one between Los Angeles and San Francisco may be considered unique. But there are plenty of precedents outside California: Dozens of similar rail projects have been built around the world, with data and lessons learned that would be highly valuable to California for assessing costs, schedules, contracting relationships, procurement, revenues, and environmental impact.

Our research appears to confirm that people are more likely to believe that a project is unique if they have no personal experience of anything similar. Consider what happened with the chief information officer of one large global logistics company that participated in our study. When we debriefed the company about its results, the CIO spotted a project described by his managers as absolutely unique, scoring a 10 on our scale. When the CIO asked which project it was, he learned that it was the installation of a standard software package for supply chain and warehouse automation in the Czech Republic. That surprised him because the company had installed this package for clients in nearly 1,000 other locations. He phoned the Czech project manager on the spot to find out what was going on. The manager explained that the project was unique because it was the first time that this software would be used in the Czech Republic.

The uniqueness trap feeds into what the Nobel laureate Daniel Kahneman called the “inside view.” When managers fall into it, they will fail to gather data and proven insights that could help them and will build budgets and schedules based only on their own beliefs and personal experiences. That can be risky: Plenty of behavioral research shows that when decision-makers do this, they tend to underestimate not only average risk but also the probability of rare, catastrophic outcomes. Another Nobel laureate, Richard Feynman, famously found that this was precisely what happened in the Challenger space shuttle disaster: The inside view of flight risk at NASA, especially among its top managers, was so narrow that it caused the agency to wildly underestimate the chances of an explosion, resulting in the tragic loss of the shuttle with all seven astronauts aboard.

"

---

### **Step 3: Generate SAT Reading and Writing Questions**

For each passage, create questions that match the **requested difficulty levels**:

- **Easy**: 20% of questions (2 questions)
- **Medium**: 30% of questions (3 questions)
- **Hard**: 50% of questions (5 questions)

Ensure the questions:

- Are aligned with the SAT Reading and Writing domains and skills.
- Include a mix of **text-based**, **graphical** (if applicable), **analytical** and **vocabulary-based** questions.
- Are clear, concise, and free from ambiguity.
- Include **answer explanations** and **score improvement tips**.
- In the questions, answers, explanations and score improvement tip, **don't show the passage number**.

---

### **Step 4: Format the Output**

Use the following **JSON template** to structure the output. Ensure all fields are completed accurately:

```json
{
  "article_title": "HERE ARE AMBIGUITIES",
  "article_author": "John Kinsella",
  "article_date": "December 18, 2023",
  "article_source": "THE NEW YORKER",
  "article_category": "Poetry",
  "article_tags": ["Nature", "Ambiguity", "Imagery"],
  "passage_list": [
    {
      "passage_number": 1,
      "text": "Here are the chaffinches we saw crossing the road dividing the forest..."
    },
    {
      "passage_number": 2,
      "text": "Here are the blue-numbered logs we saw by the fast-flowing stream..."
    },
    {
      "passage_number": 3,
      "text": "Here are the voles we saw moving through leaf litter, nibbling..."
    }
  ],
  "questions": [
    {
      "question_number": 1,
      "domain": "Information and Ideas",
      "skill": "Central Ideas and Details",
      "difficulty": "Easy",
      "passage": 1,
      "question": "What is the main idea of the first passage?",
      "options": {
        "A": "The beauty of the forest",
        "B": "The interaction between humans and nature",
        "C": "The behavior of chaffinches",
        "D": "The division of the forest by a road"
      },
      "answer": "C",
      "explanation": "The passage focuses on the chaffinches and their behavior, making C the correct answer.",
      "score_improvement_tip": "Pay attention to the central subject of the passage and avoid being distracted by secondary details."
    },
    {
      "question_number": 2,
      "domain": "Craft and Structure",
      "skill": "Words in Context",
      "difficulty": "Hard",
      "passage": 2,
      "question": "As used in line 2, 'blue-numbered logs' most likely refers to:",
      "options": {
        "A": "Logs painted blue for identification",
        "B": "Logs with natural blue markings",
        "C": "Logs used in a game",
        "D": "Logs that are wet from the stream"
      },
      "answer": "A",
      "explanation": "The phrase 'blue-numbered logs' suggests a deliberate marking system, likely for identification purposes.",
      "score_improvement_tip": "Look for contextual clues that explain unusual or specific phrases."
    }
  ],
  "scoring_guidelines": {
    "800_level_performance": "Students scoring at this level demonstrate mastery of all tested skills, including advanced analysis, synthesis, and reasoning.",
    "700_level_performance": "Students scoring at this level show strong comprehension and reasoning skills but may struggle with higher-level analysis and synthesis."
  },
  "explanation_summary": {
    "hard_questions": "Hard questions test advanced analytical and reasoning skills, often requiring students to infer meaning or analyze complex text structures.",
    "medium_questions": "Medium questions assess comprehension and vocabulary in context, with a focus on understanding main ideas and details.",
    "easy_questions": "Easy questions evaluate basic comprehension and the ability to identify explicit information in the text."
  }
}
```

---

### **Additional Instructions:**

1. **Metadata**: Fill in the metadata for the article (title, author, date, source, category, and tags).
2. **Passage Division**: Divide the article into **multiple logical passages** for question generation. And the text should keep the format as same as provided.
3. **Question Distribution**:
   - Ensure **50% of questions are hard**, **30% medium**, and **20% easy**.
   - Include at least **one question per passage**.
4. **Scoring Guidelines and Explanation Summary**:
   - Provide clear scoring guidelines for 800-level and 700-level performance.
   - Summarize the key skills tested by hard, medium, and easy questions.
5. **Readability**: Use clear and concise language for questions, answers, and explanations.

